{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTMSample.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMcQubEPe04Hy7nwMxReLZ9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VidyaValsalan/MachineLearning/blob/master/LSTMSample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73Uw1ar6sU5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBVoG3ewsYpK",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "781c54e9-c32b-424a-d3bd-7e5e22e6bca5"
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d1ad9817-d07b-44e7-ae69-08ede0b00dbc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d1ad9817-d07b-44e7-ae69-08ede0b00dbc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving excel_model_15.csv to excel_model_15 (3).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2dAXBrtsaKy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eaa1870e-1f09-4ddd-e9b8-69a0c9f14ad0"
      },
      "source": [
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User uploaded file \"excel_model_15.csv\" with length 2599 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYAGYcKasps5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "53ea24f2-9ca6-4e3e-afa6-748a58e29241"
      },
      "source": [
        "import io\n",
        "df1 = pd.read_csv(io.StringIO(uploaded['excel_model_15.csv'].decode('utf-8')),names=['date','loc1','loc2','loc3','loc4','loc5'])\n",
        "df1.head(5)\n",
        "a=input('enter the location')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "enter the locationloc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGNMhb75sxOB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "96aacabe-7320-4faa-dc33-3c6d7434b96d"
      },
      "source": [
        "df1=df1.reset_index()[a]\n",
        "df1.plot()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7da9290e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AecxefKW40IK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "77669d69-8baf-4e2e-a658-ddf96c157fc2"
      },
      "source": [
        "from pandas import read_csv\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "X = df1.values\n",
        "result = adfuller(X)\n",
        "print('ADF Statistic: %f' % result[0])\n",
        "print('p-value: %f' % result[1])\n",
        "print('Critical Values:')\n",
        "for key, value in result[4].items():\n",
        "\tprint('\\t%s: %.3f' % (key, value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ADF Statistic: -0.265211\n",
            "p-value: 0.930289\n",
            "Critical Values:\n",
            "\t1%: -3.537\n",
            "\t5%: -2.908\n",
            "\t10%: -2.591\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mnqvhOOszPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "df1=scaler.fit_transform(np.array(df1).reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E58E3hfftJOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_size=int(len(df1)*0.70)\n",
        "test_size=len(df1)-training_size\n",
        "train_data,test_data=df1[0:training_size,:],df1[training_size:len(df1),:1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUJ3iZBktc-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "def create_dataset(dataset, time_step=1):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-time_step-1):\n",
        "\t\ta = dataset[i:(i+time_step), 0]\n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[i + time_step, 0])\n",
        "\treturn numpy.array(dataX), numpy.array(dataY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ev2V4gsteR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_step = 4\n",
        "X_train, y_train = create_dataset(train_data, time_step)\n",
        "X_test, ytest = create_dataset(test_data, time_step)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4rkE4Jttj-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
        "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCqvHQCltuWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwoLaD7ztzWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Sequential()\n",
        "model.add(LSTM(50,return_sequences=True,input_shape=(4,1)))\n",
        "model.add(LSTM(50,return_sequences=True))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error',optimizer='adam')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5OrNoLQt6Q0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "5fc1c6ca-dfb7-4082-e103-96e6ebf122c4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_18 (LSTM)               (None, 4, 50)             10400     \n",
            "_________________________________________________________________\n",
            "lstm_19 (LSTM)               (None, 4, 50)             20200     \n",
            "_________________________________________________________________\n",
            "lstm_20 (LSTM)               (None, 50)                20200     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 50,851\n",
            "Trainable params: 50,851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeRFZrOLmNFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FEJc5E-uDo5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61abe1d2-30d2-4e03-aa04-9cacfabaa228"
      },
      "source": [
        "model.fit(X_train,y_train,validation_data=(X_test,ytest),epochs=1000,batch_size=64,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4147 - val_loss: 0.0101\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3943 - val_loss: 0.0085\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3742 - val_loss: 0.0070\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3538 - val_loss: 0.0057\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3328 - val_loss: 0.0047\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3107 - val_loss: 0.0039\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2876 - val_loss: 0.0034\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2632 - val_loss: 0.0034\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2375 - val_loss: 0.0041\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2105 - val_loss: 0.0055\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1824 - val_loss: 0.0079\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1534 - val_loss: 0.0117\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1240 - val_loss: 0.0172\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0950 - val_loss: 0.0249\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0673 - val_loss: 0.0354\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0425 - val_loss: 0.0492\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0228 - val_loss: 0.0669\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0109 - val_loss: 0.0883\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0095 - val_loss: 0.1117\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0191 - val_loss: 0.1327\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0349 - val_loss: 0.1459\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0472 - val_loss: 0.1498\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0503 - val_loss: 0.1456\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0451 - val_loss: 0.1361\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0353 - val_loss: 0.1239\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0250 - val_loss: 0.1110\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0167 - val_loss: 0.0988\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0115 - val_loss: 0.0879\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0094 - val_loss: 0.0789\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0096 - val_loss: 0.0716\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0112 - val_loss: 0.0660\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0135 - val_loss: 0.0619\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0158 - val_loss: 0.0592\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0176 - val_loss: 0.0576\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0187 - val_loss: 0.0570\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0191 - val_loss: 0.0574\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0186 - val_loss: 0.0587\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0176 - val_loss: 0.0606\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0160 - val_loss: 0.0633\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0143 - val_loss: 0.0666\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0125 - val_loss: 0.0703\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0110 - val_loss: 0.0744\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0098 - val_loss: 0.0786\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0091 - val_loss: 0.0828\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0090 - val_loss: 0.0865\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0093 - val_loss: 0.0896\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0098 - val_loss: 0.0918\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0105 - val_loss: 0.0930\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0109 - val_loss: 0.0930\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0111 - val_loss: 0.0919\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0109 - val_loss: 0.0899\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0104 - val_loss: 0.0872\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0098 - val_loss: 0.0840\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0092 - val_loss: 0.0806\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0086 - val_loss: 0.0771\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0083 - val_loss: 0.0739\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0081 - val_loss: 0.0710\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0081 - val_loss: 0.0685\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0082 - val_loss: 0.0664\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0083 - val_loss: 0.0648\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0084 - val_loss: 0.0636\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0084 - val_loss: 0.0629\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0083 - val_loss: 0.0625\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0081 - val_loss: 0.0625\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0079 - val_loss: 0.0627\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0076 - val_loss: 0.0631\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0074 - val_loss: 0.0636\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0072 - val_loss: 0.0640\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0071 - val_loss: 0.0644\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0070 - val_loss: 0.0646\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0069 - val_loss: 0.0645\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0069 - val_loss: 0.0642\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0069 - val_loss: 0.0636\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0068 - val_loss: 0.0626\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0067 - val_loss: 0.0615\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0066 - val_loss: 0.0601\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0064 - val_loss: 0.0586\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0063 - val_loss: 0.0570\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0061 - val_loss: 0.0554\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0060 - val_loss: 0.0539\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0059 - val_loss: 0.0525\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0058 - val_loss: 0.0513\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0057 - val_loss: 0.0502\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0057 - val_loss: 0.0493\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0056 - val_loss: 0.0485\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0055 - val_loss: 0.0478\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0054 - val_loss: 0.0473\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0053 - val_loss: 0.0468\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0051 - val_loss: 0.0463\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0050 - val_loss: 0.0459\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0049 - val_loss: 0.0454\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0049 - val_loss: 0.0448\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0048 - val_loss: 0.0442\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0047 - val_loss: 0.0434\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0046 - val_loss: 0.0426\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0045 - val_loss: 0.0417\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0044 - val_loss: 0.0407\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0043 - val_loss: 0.0398\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0042 - val_loss: 0.0388\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0042 - val_loss: 0.0378\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0041 - val_loss: 0.0369\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0040 - val_loss: 0.0360\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - val_loss: 0.0352\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0038 - val_loss: 0.0344\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - val_loss: 0.0337\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0037 - val_loss: 0.0330\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0036 - val_loss: 0.0324\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0035 - val_loss: 0.0318\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - val_loss: 0.0313\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0034 - val_loss: 0.0307\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0033 - val_loss: 0.0301\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0032 - val_loss: 0.0295\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - val_loss: 0.0288\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - val_loss: 0.0282\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - val_loss: 0.0275\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0030 - val_loss: 0.0268\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0029 - val_loss: 0.0261\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0029 - val_loss: 0.0255\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0028 - val_loss: 0.0248\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0027 - val_loss: 0.0242\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0027 - val_loss: 0.0236\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0026 - val_loss: 0.0230\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0026 - val_loss: 0.0225\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0025 - val_loss: 0.0220\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - val_loss: 0.0215\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - val_loss: 0.0210\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.0206\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - val_loss: 0.0201\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.0197\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - val_loss: 0.0192\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.0188\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.0183\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.0179\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.0174\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - val_loss: 0.0170\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.0166\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - val_loss: 0.0162\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.0158\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.0155\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.0151\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.0148\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0019 - val_loss: 0.0145\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0019 - val_loss: 0.0142\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.0139\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0019 - val_loss: 0.0136\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0019 - val_loss: 0.0133\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.0130\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.0128\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0018 - val_loss: 0.0125\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0018 - val_loss: 0.0122\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0018 - val_loss: 0.0120\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0018 - val_loss: 0.0118\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0018 - val_loss: 0.0115\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.0113\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0018 - val_loss: 0.0111\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0018 - val_loss: 0.0109\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0018 - val_loss: 0.0108\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0106\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0104\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0103\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0101\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0100\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0098\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - val_loss: 0.0097\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0095\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0094\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0093\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0092\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0091\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0090\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0089\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0088\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.0087\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0086\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0086\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0085\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0084\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0084\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0083\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0082\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0082\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0081\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.0081\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.0081\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0080\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0080\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0080\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0079\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0079\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0079\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0078\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0078\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0078\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0078\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0077\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0077\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0077\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0077\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0077\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0077\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0077\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.0077\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0017 - val_loss: 0.0076\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0074\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0074\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0074\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.0074\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0074\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0074\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.0074\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0074\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.0074\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0074\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0074\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0074\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0074\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0074\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0074\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0074\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0073\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.0073\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0073\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0073\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0073\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0073\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0073\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0073\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0073\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0073\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0073\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.0073\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - val_loss: 0.0073\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0073\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.0072\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0072\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0072\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0072\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0072\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.0072\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0072\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - val_loss: 0.0072\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0072\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0072\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0072\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0072\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0072\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0072\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0071\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0071\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - val_loss: 0.0071\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0071\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0071\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0071\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.0071\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0071\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0071\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0071\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0071\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0017 - val_loss: 0.0071\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0071\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0071\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0070\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0070\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0070\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0070\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0070\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0070\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0070\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0070\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.0070\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0070\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0070\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0070\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0070\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.0070\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0069\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0069\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0069\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0069\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0069\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0069\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0069\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.0069\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0069\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.0069\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0069\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0069\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0017 - val_loss: 0.0069\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0069\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.0068\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0068\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0068\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0068\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0068\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0068\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0068\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0068\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.0068\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0068\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0068\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0068\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0068\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0068\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.0067\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0067\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0067\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0067\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.0067\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.0067\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0067\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0067\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0067\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0067\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0067\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0067\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0067\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0017 - val_loss: 0.0066\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0066\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0066\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.0066\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0066\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0066\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0066\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0017 - val_loss: 0.0066\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0017 - val_loss: 0.0066\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0066\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.0066\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0066\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0066\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0066\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0065\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0065\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0065\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.0065\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.0065\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.0065\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0017 - val_loss: 0.0065\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0065\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0065\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0065\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0065\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0065\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0065\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0064\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0064\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0064\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - val_loss: 0.0064\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.0064\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0064\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.0064\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.0064\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0064\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0064\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0064\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0064\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.0064\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0064\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.0063\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0063\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0063\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0063\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0063\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0063\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0063\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0063\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.0063\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0063\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0063\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0063\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0063\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.0062\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.0062\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0062\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.0062\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0062\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - val_loss: 0.0062\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0062\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0062\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0062\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0062\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0062\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.0062\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.0062\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0061\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0017 - val_loss: 0.0061\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0061\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - val_loss: 0.0061\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.0061\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0061\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - val_loss: 0.0061\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0061\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.0061\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0061\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0061\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0017 - val_loss: 0.0061\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0061\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0060\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0060\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0060\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0060\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0060\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0060\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0060\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - val_loss: 0.0060\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.0060\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0060\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0060\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0060\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0060\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.0058\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0058\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0058\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0058\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0058\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0058\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0058\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.0058\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0058\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - val_loss: 0.0058\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.0058\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0058\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.0058\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0057\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0057\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0057\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0057\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0057\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.0057\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - val_loss: 0.0057\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0057\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0057\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0057\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0057\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0057\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0057\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0056\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - val_loss: 0.0056\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0056\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - val_loss: 0.0056\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0056\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0056\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0056\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0056\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0056\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0056\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0056\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.0056\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - val_loss: 0.0056\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0052\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0052\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0052\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0052\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0052\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0052\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0052\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0052\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0016 - val_loss: 0.0052\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0052\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0052\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0052\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0052\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0051\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0051\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0051\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0051\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0051\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0051\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0051\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0051\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.0051\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.0051\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.0051\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - val_loss: 0.0051\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.0051\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0051\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0050\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - val_loss: 0.0050\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0050\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0050\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0050\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.0050\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0016 - val_loss: 0.0050\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0050\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0050\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0050\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - val_loss: 0.0050\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0050\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0050\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0049\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0049\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - val_loss: 0.0049\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.0049\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0049\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0049\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0049\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - val_loss: 0.0049\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0049\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0049\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0049\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0049\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0049\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.0048\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.0048\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0048\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0048\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - val_loss: 0.0048\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0048\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0048\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0048\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0048\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0048\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0048\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0048\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0048\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - val_loss: 0.0048\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0047\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0047\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0047\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0047\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0047\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0047\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0047\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0047\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0047\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.0047\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0047\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0047\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0047\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0046\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0046\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0046\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0046\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0046\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0046\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.0046\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0046\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0046\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0046\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0046\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0046\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.0046\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0046\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0044\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0044\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0044\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0044\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0044\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0044\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0044\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - val_loss: 0.0044\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0044\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0044\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.0044\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0044\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0044\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0043\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0043\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0043\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - val_loss: 0.0043\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0043\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0043\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0043\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0043\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0043\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0043\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0043\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0043\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0043\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - val_loss: 0.0043\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0042\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0042\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.0042\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0042\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0042\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0042\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0042\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0042\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - val_loss: 0.0042\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0042\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0042\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0042\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0042\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0042\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0041\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0041\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0041\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0041\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.0041\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0016 - val_loss: 0.0041\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0041\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0041\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0041\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0041\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0041\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0041\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0041\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0041\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0016 - val_loss: 0.0041\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0040\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0040\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0040\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0040\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0040\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0040\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0040\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0040\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0040\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0040\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0040\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0040\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0040\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0040\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0039\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0039\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0039\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0039\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.0039\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0039\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0039\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0039\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0039\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0039\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0039\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0039\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0039\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0039\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0036\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0036\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0036\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0036\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0036\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0036\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0036\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0036\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - val_loss: 0.0036\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.0036\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.0036\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0036\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0036\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.0036\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0036\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0035\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0035\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0035\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - val_loss: 0.0035\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0035\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.0035\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0035\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0035\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0035\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0035\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0035\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0035\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0035\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - val_loss: 0.0035\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0035\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.0034\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0032\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0032\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0032\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0032\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0032\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0032\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0032\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.0032\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0032\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0032\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0032\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0032\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0032\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0032\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - val_loss: 0.0032\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0032\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0030\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0023\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0016 - val_loss: 0.0023\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0023\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0023\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0023\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0023\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0023\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0023\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7dac148e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnpyodiHuSPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "train_predict=model.predict(X_train)\n",
        "test_predict=model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e65sCWLWuhoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_predict=scaler.inverse_transform(train_predict)\n",
        "test_predict=scaler.inverse_transform(test_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN2Rq7cGuqtg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "392d12e9-ba14-4669-9dcc-0864c72dad64"
      },
      "source": [
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "math.sqrt(mean_squared_error(y_train,train_predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67.97742306891148"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xtx4blQyu7OB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9c9e99c-dfc6-4e87-d1eb-f1d65b018a88"
      },
      "source": [
        "math.sqrt(mean_squared_error(ytest,test_predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140.70943124358018"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YER68jKLwNlL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "7e4585fe-8635-44ec-e718-2172a94e3439"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "look_back=4\n",
        "trainPredictPlot = numpy.empty_like(df1)\n",
        "trainPredictPlot[:, :] = np.nan\n",
        "trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
        "testPredictPlot = numpy.empty_like(df1)\n",
        "testPredictPlot[:, :] = numpy.nan\n",
        "testPredictPlot[len(train_predict)+(look_back*2)+1:len(df1)-1, :] = test_predict\n",
        "plt.plot(scaler.inverse_transform(df1))\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}